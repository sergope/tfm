{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "normalize_data_functions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPkciWKXz/kSFvrkGU0OkW7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sergope/tfm/blob/main/normalize_data_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWrueRos7C3Y",
        "outputId": "050490d9-cacb-4f35-e3c9-8f65ff777212",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Conectar el notebook con la cuenta de gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=False)\n",
        "\n",
        "BASE_FOLDER = 'drive/My Drive/TFM/resources/'\n",
        "\n",
        "# 4/5QEd0fKmDZNAa31VQJkz2jbunYtoTkIO7_mXkg-i3fTokiPDB8cmJxc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8QqcUng7Sd-"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UCG_R4u7ap2"
      },
      "source": [
        "# DATE FUNCTIONS\n",
        "def date_normalized_row(row):\n",
        "  mes = str(row['MES'])\n",
        "  if (row['MES'] < 10):\n",
        "    mes = '0' + str(row['MES'])\n",
        "\n",
        "  dia = str(row['DIA'])\n",
        "  if (row['DIA'] < 10):\n",
        "    dia = '0' + str(row['DIA'])\n",
        "\n",
        "  date_normalized = str(row['ANO']) + '-' + mes + '-' + dia\n",
        "  return date_normalized\n",
        "\n",
        "def date_normalized(table):\n",
        "  table['ds'] = table.apply(lambda row: date_normalized_row(row), axis=1)\n",
        "  return table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn5_SC2R7alH"
      },
      "source": [
        "# MAGNITUDE FUNCTIONS\n",
        "def filter_by_magnitude(table, magnitude):\n",
        "  return table.loc[(table['MAGNITUD'] == magnitude)]\n",
        "\n",
        "def extract_daily_max_magnitude(table):\n",
        "  hours_range = ['H01','H02','H03','H04','H05','H06','H07','H08','H09','H10','H11','H12','H13','H14','H15','H16','H17','H18','H19','H20','H21','H22','H23','H24',]\n",
        "  table['y'] = table.loc[:, hours_range].max(axis=1)\n",
        "  return table\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88R4VG_ocOEu"
      },
      "source": [
        "# CLEAN TABLE FUNCTIONS\n",
        "def filter_columns(table, columns_list):\n",
        "  return table.filter(columns_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xf1bD3HVY1Fb"
      },
      "source": [
        "def prophet_data_normalized_one_magnitude(file_name, magnitude):\n",
        "  #1- LEO CSV HISTORICO DE UNA ESTACIÓN\n",
        "  table = pd.read_table(BASE_FOLDER+'processed_data/' + file_name + '.csv', sep=';', engine='python')\n",
        "  #2- FORMATEO FECHA\n",
        "  table = date_normalized(table)\n",
        "  #3- FILTRO POR MAGNITUD\n",
        "  table = filter_by_magnitude(table, magnitude)\n",
        "  #4- MAXIMO DIARIO\n",
        "  table = extract_daily_max_magnitude(table)\n",
        "  #4.1- COMPROBAR QUE LAS MEDIDAS ESTÁN VERIFICADAS\n",
        "  #5- ELIMINAR COLUMNAS INNECESARIAS\n",
        "  table = filter_columns(table, ['ds', 'y'])\n",
        "  #6- ELIMINAR NAN\n",
        "  table.dropna(inplace=True)\n",
        "  #7- ACTUALIAR ÍNDICE\n",
        "  table.reset_index(drop=True, inplace=True)\n",
        "  #8- DEVOLVEMOS LA TABLA\n",
        "  return table\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug08PLURC-Gb"
      },
      "source": [
        "# Normalize aemet data\n",
        "def normalize_aemet_data(file_name, columns_to_filter):\n",
        "  table = pd.read_table(BASE_FOLDER+'processed_data/' + file_name + '.csv', sep=';', engine='python')\n",
        "  table.rename(columns={\"FECHA\": \"ds\"}, inplace=True)\n",
        "  columns_with_date = columns_to_filter.copy()\n",
        "  columns_with_date.append('ds')\n",
        "  table = filter_columns(table, columns_with_date)\n",
        "  table.drop_duplicates(subset =\"ds\", keep = 'last', inplace = True) \n",
        "  for column in table.columns:\n",
        "    table = table[table[column] != 'Ip']\n",
        "    table[column] = table[column].str.replace(',', '.')\n",
        "\n",
        "  return table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbNW3VPw-9F3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}